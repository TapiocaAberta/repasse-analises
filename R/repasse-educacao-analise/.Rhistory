train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
View(test_data)
library(neuralnet)
View(train_data)
#Fit de neuralnet
#Executar testes com diferentes arquiteturas
nn <- neuralnet(
VALORREPASSEEDUCACAO ~ IDEB_NOTA+IDHEDUCACAO+IDHLONGEVIDADE+IDHM+IDHRENDA,
data=train_data,hidden=c(5,4,3,2),linear.output=T)
plot(nn)
View(test_data)
pr.nn <- compute(nn,test_data[,1:5])
View(pr.nn)
pr.nn_ <- pr.nn$net.result*(max(ideb_repasse$VALORREPASSEEDUCACAO)-min(ideb_repasse$VALORREPASSEEDUCACAO))+min(ideb_repasse$VALORREPASSEEDUCACAO)
pr.nn_
test.r <- (test_data$VALORREPASSEEDUCACAO)*(max(ideb_repasse$VALORREPASSEEDUCACAO)-min(ideb_repasse$VALORREPASSEEDUCACAO))+min(ideb_repasse$VALORREPASSEEDUCACAO)
View(test_data)
MSE_nn <- mean((pr.nn_ - test.r)^2)
df <- data.frame(test_data, predict_nn=pr.nn_)
View(df)
test.r
df <- data.frame(valor=test.r, predict_nn=pr.nn_)
View(df)
plot(test_data$VALORREPASSEEDUCACAO,type = 'l',col="red",xlab = "x", ylab = "Valor Residencia")
lines(pr.nn$net.result,col = "blue")
View(df)
View(test_data)
pr.nn
pr.nn$net.result
data_num2 <- select(ideb_repasse, coluns)
data_num2 <- select(ideb_repasse, coluns_name)
library("dplyr")
set.seed(0)
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
View(ideb_repasse)
coluns_name <- c('IDEB_NOTA', 'IDHEDUCACAO', 'IDHLONGEVIDADE', 'IDHM', 'IDHRENDA', 'VALORREPASSEEDUCACAO')
data_num2 <- select(ideb_repasse, coluns_name)
data_num2 <- select(ideb_repasse,
c('IDEB_NOTA', 'IDHEDUCACAO', 'IDHLONGEVIDADE', 'IDHM', 'IDHRENDA', 'VALORREPASSEEDUCACAO'))
View(ideb_repasse)
data_num2 <- select(ideb_repasse,
c('IDEB_NOTA', 'IDH_EDUCACAO', 'IDH_LONGEVIDADE', 'IDHM', 'IDH_RENDA', 'VALOR_REPASSE_EDUCACAO'))
data_num2 <- select(ideb_repasse,
c('IDEB_NOTA', 'IDH_EDUCACAO', 'IDH_LONGEVIDADE', 'IDHM', 'IDH_RENDA', 'VALOR_REPASSADO_EDUCACAO'))
max_data <- apply(data_num2, 2, max)
min_data <- apply(data_num2, 2, min)
scaled <- scale(data_num2,center = min_data, scale = max_data - min_data)
index = sample(1:nrow(ideb_repasse),round(0.70*nrow(ideb_repasse)))
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
library(neuralnet)
#Fit de neuralnet
#Executar testes com diferentes arquiteturas
nn <- neuralnet(
VALORREPASSEEDUCACAO ~ IDEB_NOTA+IDHEDUCACAO+IDHLONGEVIDADE+IDHM+IDHRENDA,
data=train_data,hidden=c(5,4,3,2),linear.output=T)
#Fit de neuralnet
#Executar testes com diferentes arquiteturas
nn <- neuralnet(
VALOR_REPASSADO_EDUCACAO ~ IDEB_NOTA+IDH_EDUCACAO+IDH_LONGEVIDADE+IDHM+IDH_RENDA,
data=train_data,hidden=c(5,4,3,2),linear.output=T)
plot(nn)
pr.nn <- compute(nn,test_data[,1:5])
pr.nn_ <- pr.nn$net.result*(max(ideb_repasse$VALORREPASSEEDUCACAO)- min(ideb_repasse$VALORREPASSEEDUCACAO))+min(ideb_repasse$VALORREPASSEEDUCACAO)
test.r <- (test_data$VALORREPASSEEDUCACAO)*(max(ideb_repasse$VALORREPASSEEDUCACAO)-min(ideb_repasse$VALORREPASSEEDUCACAO))+min(ideb_repasse$VALORREPASSEEDUCACAO)
df <- data.frame(valor=test.r, predict_nn=pr.nn_)
pr.nn <- compute(nn,test_data[,1:5])
View(pr.nn)
pr.nn$net.result
pr.nn <- compute(nn,test_data[,1:5])
pr.nn_ <- pr.nn$net.result*(max(ideb_repasse$VALOR_REPASSADO_EDUCACAO)- min(ideb_repasse$VALOR_REPASSADO_EDUCACAO))+min(ideb_repasse$VALOR_REPASSADO_EDUCACAO)
test.r <- (test_data$VALOR_REPASSADO_EDUCACAO)*(max(ideb_repasse$VALOR_REPASSADO_EDUCACAO)-min(ideb_repasse$VALOR_REPASSADO_EDUCACAO))+min(ideb_repasse$VALOR_REPASSADO_EDUCACAO)
df <- data.frame(valor=test.r, predict_nn=pr.nn_)
View(df)
MSE_nn <- mean((pr.nn_ - test.r)^2)
MSE_nn
plot(test_data$VALORREPASSEEDUCACAO,type = 'l',col="red",xlab = "x", ylab = "Valor Repassado")
plot(test_data$VALOR_REPASSADO_EDUCACAO,type = 'l',col="red",xlab = "x", ylab = "Valor Repassado")
lines(pr.nn$net.result,col = "blue")
table(test_data$VALOR_REPASSADO_EDUCACAO,pr.nn$net.result)
#Baixa os dados
data <- Boston
#install.packages("MASS")
library("MASS")
library("rpart")
set.seed(0)
#Baixa os dados
data <- Boston
#Uma olhada nos dados
head(data)
#Temos valores nulos?
data[is.na(data) == TRUE]
#Train-Test Split
train_test_split_index <- 0.8 * nrow(data)
train <- data.frame(data[1:train_test_split_index,])
test <- data.frame(data[(train_test_split_index+1): nrow(data),])
# árvore
fit_tree <- rpart(medv ~.,method="anova", data=train)
tree_predict <- predict(fit_tree,test)
mse_tree <- mean((tree_predict - test$medv)^2)
#Conceito de função
# y = f(x)
# y = a +b1*x1 +b2*x2...
#install.packages("MASS")
library("MASS")
library("rpart")
set.seed(0)
#Baixa os dados
data <- Boston
#Uma olhada nos dados
head(data)
#Temos valores nulos?
data[is.na(data) == TRUE]
#Train-Test Split
train_test_split_index <- 0.8 * nrow(data)
train <- data.frame(data[1:train_test_split_index,])
test <- data.frame(data[(train_test_split_index+1): nrow(data),])
#CART
# árvore
fit_tree <- rpart(medv ~.,method="anova", data=train)
tree_predict <- predict(fit_tree,test)
mse_tree <- mean((tree_predict - test$medv)^2)
#Padronizar dados para melhor performance
#Explicar apply
set.seed(0)
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
index = sample(1:nrow(data),round(0.70*nrow(data)))
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
library(neuralnet)
#abrir o CRAN para mostrar
#Fit de neuralnet
#Executar testes com diferentes arquiteturas
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,data=train_data,hidden=c(5,4,3,2),linear.output=T)
plot(nn)
pr.nn <- compute(nn,test_data[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (test_data$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
plot(test_data$medv,type = 'l',col="red",xlab = "x", ylab = "Valor Residencia")
lines(pr.nn$net.result,col = "blue")
library(ISLR)
library(neuralnet)
#Olhar os dados - data wrangling?
data <- College
#is.na(data)
#View(data)
#private = as.numeric(College$Private)-1
private <- ifelse(data$Private == 'Yes', 1, 0)
#Padronizar dados para melhor performance
data <- data[,2:18]
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- data.frame(scale(data,center = min_data, scale = max_data - min_data))
#Inclui variável explicada (target)
scaled$Private <- private
set.seed(0)
#train test split
index = sample(1:nrow(data),round(0.70*nrow(data)))
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
#Utiliza o neuralnet
set.seed(0)
n = names(train_data)
f <- as.formula(paste("Private ~", paste(n[!n %in% "Private"], collapse = " + ")))
nn <- neuralnet(f,data=train_data,hidden=c(5,4),linear.output=F)
plot(nn)
pr.nn <- compute(nn,test_data[,1:17])
#Explica sapply
pr.nn$net.result <- sapply(pr.nn$net.result,round,digits=0)
pr.nn$net.result
table(test_data$Private,pr.nn$net.result)
Acc <- (62+158) / (62+158+7+6)
#CART comparação
set.seed(0)
# árvore
fit_tree <- rpart(f,method="class", data=train_data)
tree_predict <- predict(fit_tree,test_data,type = "class")
table(test_data$Private,tree_predict)
Acc_tree <- (58+159) / (58+159+11+5)
nn2 <- neuralnet(
VALOR_REPASSADO_EDUCACAO ~ IDEB_NOTA+IDH_EDUCACAO,
data=train_data,hidden=c(5,4,3,2),linear.output=T)
nn2 <- neuralnet(
VALOR_REPASSADO_EDUCACAO ~ IDEB_NOTA+IDH_EDUCACAO,
data=train_data,hidden=c(5,4,3,2),linear.output=T)
set.seed(0)
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
data_num2 <- select(ideb_repasse,
c('IDEB_NOTA', 'IDH_EDUCACAO', 'IDH_LONGEVIDADE', 'IDHM', 'IDH_RENDA', 'VALOR_REPASSADO_EDUCACAO'))
max_data <- apply(data_num2, 2, max)
min_data <- apply(data_num2, 2, min)
scaled <- scale(data_num2,center = min_data, scale = max_data - min_data)
library("dplyr")
set.seed(0)
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
data_num2 <- select(ideb_repasse,
c('IDEB_NOTA', 'IDH_EDUCACAO', 'IDH_LONGEVIDADE', 'IDHM', 'IDH_RENDA', 'VALOR_REPASSADO_EDUCACAO'))
head(ideb_repasse)
data <- select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
data <- select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
data <- select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
library("dplyr")
data <- select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
data <- dplyr::select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
View(data)
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
max_data
min_data
scaled <- data.frame(scale(data,center = min_data, scale = max_data - min_data))
View(scaled)
set.seed(0)
#train test split
index = sample(1:nrow(data),round(0.70*nrow(data)))
index
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
View(train_data)
#Utiliza o neuralnet
set.seed(0)
n = names(train_data)
n
f <- as.formula(paste("VALOR_REPASSADO_EDUCACAO ~", paste(n[!n %in% "VALOR_REPASSADO_EDUCACAO"], collapse = " + ")))
f
nn <- neuralnet(f,data=train_data,hidden=c(5,4),linear.output=F)
plot(nn)
View(test_data)
pr.nn <- compute(nn,test_data[,2:3])
pr.nn_ <- pr.nn$net.result*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
test.r <- (test_data$VALOR_REPASSADO_EDUCACAO)*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
View(pr.nn_)
test.r
MSE_nn <- mean((pr.nn_ - test.r)^2)
MSE_nn
df <- data.frame(test.r, pr.nn)
View(df)
df <- data.frame(test.r, pr.nn_)
View(df)
library("dplyr")
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
data <- dplyr::select(ideb_repasse, c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO'))
set.seed(0)
train_data <- as.data.frame(data[index,])
#train test split
index = sample(1:nrow(data),round(0.70*nrow(data)))
train_data <- as.data.frame(data[index,])
test_data <- as.data.frame(data[-index,])
#Utiliza o neuralnet
set.seed(0)
n = names(train_data)
f <- as.formula(paste("VALOR_REPASSADO_EDUCACAO ~", paste(n[!n %in% "VALOR_REPASSADO_EDUCACAO"], collapse = " + ")))
nn <- neuralnet(f,data=train_data,hidden=c(5,4),linear.output=F)
pr.nn <- compute(nn,test_data[,2:3])
pr.nn$net.result
test_data
test_data[,2:3]
pr.nn <- compute(nn,test_data[,2:3])
pr.nn$neurons
pr.nn$net.result
n = names(ideb_repasse)
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
a.
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
head(ideb_repasse)
n = names(ideb_repasse)
n
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
head(ideb_repasse)
data <- dplyr::select(ideb_repasse,
c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO', 'IDHM',
'IDH_LONGEVIDADE', 'IDH_RENDA'))
View(data)
scaled <- data.frame(scale(data,center = min_data, scale = max_data - min_data))
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- data.frame(scale(data,center = min_data, scale = max_data - min_data))
set.seed(0)
#train test split
index = sample(1:nrow(data),round(0.70*nrow(data)))
index
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
#Utiliza o neuralnet
set.seed(0)
n = names(train_data)
f <- as.formula(paste("VALOR_REPASSADO_EDUCACAO ~", paste(n[!n %in% "VALOR_REPASSADO_EDUCACAO"], collapse = " + ")))
f
nn <- neuralnet(f,data=train_data,hidden=c(5,4),linear.output=F)
pr.nn <- compute(nn,test_data[,2:3])
View(test_data)
pr.nn <- compute(nn,test_data[,2:6])
pr.nn_ <- pr.nn$net.result*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
test.r <- (test_data$VALOR_REPASSADO_EDUCACAO)*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
df <- data.frame(test.r, pr.nn_)
View(df)
MSE_nn <- mean((pr.nn_ - test.r)^2)
MSE_nn
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
data <- dplyr::select(ideb_repasse,
c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO', 'IDHM',
'IDH_LONGEVIDADE', 'IDH_RENDA'))
#Train-Test Split
train_test_split_index <- 0.8 * nrow(data)
train <- data.frame(data[1:train_test_split_index,])
test <- data.frame(data[(train_test_split_index+1): nrow(data),])
View(train)
View(train)
# árvore
fit_tree <- rpart(VALOR_REPASSADO_EDUCACAO ~.,method="anova", data=train)
tree_predict <- predict(fit_tree,test)
mse_tree <- mean((tree_predict - test$VALOR_REPASSADO_EDUCACAO)^2)
mse_tree
df_tree <- data.frame(tree_predict, test$VALOR_REPASSADO_EDUCACAO)
View(df_tree)
library("dplyr")
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
#ideb_repasse[is.na(ideb_repasse) == TRUE]
ideb_repasse <- na.omit(ideb_repasse)
head(ideb_repasse)
data <- dplyr::select(ideb_repasse,
c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO', 'IDHM',
'IDH_LONGEVIDADE', 'IDH_RENDA'))
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
max_data
min_data
scaled <- data.frame(scale(data,center = min_data, scale = max_data - min_data))
set.seed(0)
#train test split
index = sample(1:nrow(data),round(0.70*nrow(data)))
index
train_data <- as.data.frame(scaled[index,])
test_data <- as.data.frame(scaled[-index,])
#Utiliza o neuralnet
set.seed(0)
n = names(train_data)
n
f <- as.formula(paste("VALOR_REPASSADO_EDUCACAO ~", paste(n[!n %in% "VALOR_REPASSADO_EDUCACAO"], collapse = " + ")))
f
nn <- neuralnet(f,data=train_data,hidden=c(5,4),linear.output=F)
plot(nn)
pr.nn <- compute(nn,test_data[,2:6])
pr.nn_ <- pr.nn$net.result*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
test.r <- (test_data$VALOR_REPASSADO_EDUCACAO)*(max(data$VALOR_REPASSADO_EDUCACAO)-min(data$VALOR_REPASSADO_EDUCACAO))+min(data$VALOR_REPASSADO_EDUCACAO)
MSE_nn <- mean((pr.nn_ - test.r)^2)
MSE_nn
mse_tree
4931892.7
options(scipen = 100)
mse_tree
MSE_nn
install.packages("ggpubr")
library("ggpubr")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO, ideb_repasse$IDEB_NOTA, method = "pearson")
# mpg
ggqqplot(ideb_repasse$VALOR_REPASSADO_EDUCACAO, ylab = "VALOR_REPASSADO_EDUCACAO")
# wt
ggqqplot(ideb_repasse$IDEB_NOTA, ylab = "IDEB_NOTA")
ggscatter(ideb_repasse, x = "VALOR_REPASSADO_EDUCACAO", y = "IDEB_NOTA",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "$", ylab = "Nota")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO
method = "pearson")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO
method = "pearson")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO,
method = "pearson")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO,
method = "pearson")
cor.test(c(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO),
method = "pearson")
cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO,
c(ideb_repasse$IDEB_NOTA,
ideb_repasse$IDH_EDUCACAO),
method = "pearson")
library("rnn")
library("dplyr")
ideb_repasse <- read.csv(file = "../../data/ideb_repasse/ideb_repasse.csv")
ideb_repasse <- na.omit(ideb_repasse)
View(ideb_repasse)
summary(ideb_repasse)
as.Date.numeric(ideb_repasse$ANO_IDEB)
as.Date(ideb_repasse$ANO_IDEB)
as.Date(x = ideb_repasse$ANO_IDEB)
as.Date(x = ideb_repasse$ANO_IDEB, ideb_repasse)
summary(ideb_repasse)
head(ideb_repasse)
imdb <- dataset_imdb(num_words = 500)
imdb <- dataset_imdb(num_words = 500)
library(keras)
install.packages("keras", "tensorflow")
install.packages("keras", "tensorflow")
install.packages("keras", "tensorflow")
library(keras)
library(tensorflow)
use_condaenv("keras-tf", required = T)
imdb <- dataset_imdb(num_words = 500)
y[]
use_condaenv("keras-tf", required = T)
imdb <- dataset_imdb(num_words = 500)
plot(ideb_repasse$VALOR_REPASSADO_EDUCACAO)
plot(ideb_repasse$VALOR_REPASSADO_EDUCACAO, type = "l")
head(ideb_repasse, n = 4)
source("~/workspace/code/pessoal/repasse-analises/R/repasse-educacao-analise/teste_temporal.R", echo=TRUE)
head(ideb_repasse, n = 5)
head(ideb_repasse, n = 5)
View(ideb_repasse)
plot(ideb_repasse$IDH_EDUCACAO, type = "l")
plot(ideb_repasse$IDEB_NOTA, type = "l")
lines(ideb_repasse$VALOR_REPASSADO_EDUCACAO, type="l", col = "darkblue")
plot(ideb_repasse$IDEB_NOTA, type = "l")
lines(ideb_repasse$VALOR_REPASSADO_EDUCACAO, type="l", col = "darkblue")
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
library("ggpubr")
head(ideb_repasse)
ggscatter(ideb_repasse, x = "VALOR_REPASSADO_EDUCACAO", y = "IDEB_NOTA",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Valor Repassado para Educação em Reais", ylab = "Nota ideb")
shapiro.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO)
shapiro.test(ideb_repasse$IDEB_NOTA)
# VALOR_REPASSADO_EDUCACAO
ggqqplot(ideb_repasse$VALOR_REPASSADO_EDUCACAO, ylab = "MPG")
# IDEB_NOTA
ggqqplot(ideb_repasse$IDEB_NOTA, ylab = "WT")
res <- cor.test(ideb_repasse$VALOR_REPASSADO_EDUCACAO, ideb_repasse$IDEB_NOTA,
method = "pearson")
res
install.packages("corrplot")
library(corrplot)
corrplot(ideb_repasse, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
data <- dplyr::select(ideb_repasse,
c('VALOR_REPASSADO_EDUCACAO', 'IDEB_NOTA', 'IDH_EDUCACAO', 'IDHM',
'IDH_LONGEVIDADE', 'IDH_RENDA'))
corrplot(data, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
View(res)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
corrplot(data, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
head(data)
?corp
?corrplot
res2 <- cor(data)
View(res2)
corrplot(res2, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
round(res2, 2)
install.packages("Hmisc")
library("Hmisc")
res2 <- rcorr(as.matrix(my_data))
library("Hmisc")
install.packages("Hmisc")
library("Hmisc")
res2 <- rcorr(as.matrix(my_data))
install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")
chart.Correlation(data, histogram=TRUE, pch=19)
chart.Correlation(data, histogram=TRUE)
chart.Correlation(data, histogram=TRUE)
chart.Correlation(data, histogram=TRUE)
corrplot(res2, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
ggscatter(ideb_repasse, x = "IDH_EDUCACAO", y = "IDEB_NOTA",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Valor Repassado para Educação em Reais", ylab = "Nota ideb")
ggscatter(ideb_repasse, x = "VALOR_REPASSADO_EDUCACAO", y = "IDH_EDUCACAO",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "Valor Repassado para Educação em Reais", ylab = "Nota ideb")
library("Hmisc")
')
install.packages('Hmisc')
install.packages("Hmisc")
R CMD INSTALL latticeExtra_0.6-28.tar
devtools::install_version("latticeExtra")
devtools::install_version("jpeg")
devtools::install_version("latticeExtra")
devtools::install_version("latticeExtra", repos="https://www.stats.bris.ac.uk/R/")
gc()
